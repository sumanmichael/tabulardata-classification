{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tabulardata-classification-stacking-and-tabnet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sumanmichael/tabulardata-classification-deeplearning/blob/main/tabulardata_classification_stacking_and_tabnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-rM_5g5T5nu",
        "outputId": "6226bb9d-533a-46e8-f664-32878518a5e7"
      },
      "source": [
        "!pip install vecstack lightgbm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: vecstack in /usr/local/lib/python3.6/dist-packages (0.4.0)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.6/dist-packages (2.2.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from vecstack) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from vecstack) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from vecstack) (1.18.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->vecstack) (0.17.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbGAuIBniAIo"
      },
      "source": [
        "# import numpy as np\n",
        "# import warnings\n",
        "# warnings.filterwarnings(\"ignore\")\n",
        "# import pandas as pd\n",
        "# df=pd.read_csv(\"https://dphi.s3.ap-south-1.amazonaws.com/dataset/train_age_dataset.csv\")\n",
        "# import matplotlib.pyplot as plt\n",
        "# from sklearn.preprocessing import QuantileTransformer\n",
        "# import seaborn as sns\n",
        "# df.drop(['Unnamed: 0', 'userId','age_group'],axis=1,inplace=True)\n",
        "\n",
        "\n",
        "# for col in list(set(df.columns)-set(['tier','gender','age_group'])):\n",
        "    \n",
        "#     fig, (ax1, ax2, ax3) = plt.subplots(1,3,figsize=(20,5))\n",
        "#     sns.histplot(df[col],ax=ax1,kde=True)\n",
        "    \n",
        "#     ax1.set_ylabel(\"\") \n",
        "#     percentiles = df[col].quantile([0.01,0.99]).values\n",
        "#     df[col] = np.clip(df[col], percentiles[0], percentiles[1])\n",
        "   \n",
        "#     sns.histplot(df[col],ax=ax2,kde=True)\n",
        "    \n",
        "#     ax2.set_ylabel(\"\")  \n",
        "    \n",
        "#     quantile_transformer =QuantileTransformer(random_state=0)\n",
        "#     df[col] = quantile_transformer.fit_transform(np.array(df[col]).reshape(-1,1))\n",
        "    \n",
        "#     sns.histplot(df[col],ax=ax3,kde=True)\n",
        "#     ax3.set_ylabel(\"\")  \n",
        "#     plt.show()\n",
        "#     break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFVfE97f8P1R"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2tZX0HFUMTT"
      },
      "source": [
        "df = pd.read_csv(\"https://dphi.s3.ap-south-1.amazonaws.com/dataset/train_age_dataset.csv\")\n",
        "X_final = pd.read_csv(\"https://dphi.s3.ap-south-1.amazonaws.com/dataset/test_age_dataset.csv\")\n",
        "X = df.iloc[:,:-1]\n",
        "y = df.iloc[:,-1]\n",
        "\n",
        "remCol=[]\n",
        "for c in X.columns:\n",
        "    if(len(X[c].unique())/len(df))>=0.99:\n",
        "        remCol.append(c)\n",
        "X.drop(remCol,axis=1,inplace=True)\n",
        "X_final.drop(remCol,axis=1,inplace=True)\n",
        "\n",
        "X = pd.get_dummies(X,columns=[\"tier\",\"gender\"],drop_first=True)\n",
        "X_final = pd.get_dummies(X_final,columns=[\"tier\",\"gender\"],drop_first=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rc7BrUEv9kRy"
      },
      "source": [
        "# Correlation Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G46Rjab-ZuEX"
      },
      "source": [
        "# f, ax = plt.subplots(figsize=(11, 9))\n",
        "# sns.heatmap(X.corr())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TO6rU3IscD3j"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "corr = X.corr()\n",
        "columns = np.full((corr.shape[0],), True, dtype=bool)\n",
        "for i in range(corr.shape[0]):\n",
        "    for j in range(i+1, corr.shape[0]):\n",
        "        if corr.iloc[i,j] >= 0.9:\n",
        "            if columns[j]:\n",
        "                columns[j] = False\n",
        "selected_columns = X.columns[columns]\n",
        "X=X[selected_columns]\n",
        "X_final = X_final[selected_columns]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QV5wB7DdcNl0"
      },
      "source": [
        "# sns.heatmap(X.corr())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXGDHA93-AvB"
      },
      "source": [
        "# Outliers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pm3DD21LJZQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vau2CH04LhRx"
      },
      "source": [
        "# from sklearn.preprocessing import QuantileTransformer\n",
        "# SUBSET = 5000\n",
        "# X_Sampled = X[:SUBSET_SIZE]\n",
        "# for col in X_Sampled.columns[:]:\n",
        "#     plt.figure()\n",
        "#     y = X_Sampled[[col]].values\n",
        "#     # y = QuantileTransformer(output_distribution='normal').fit_transform(y)\n",
        "#     sns.distplot(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oP4VpQKrURif"
      },
      "source": [
        "# pd.get_dummies(df[[\"tier\"]],columns=[\"tier\"])[\"tier_3\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IV0KtPjVWPCJ"
      },
      "source": [
        "# X[\"tier_3\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzCT64hTAMVA"
      },
      "source": [
        "from scipy import stats\n",
        "\n",
        "inlier_idx = (np.abs(stats.zscore(X)) < 3).all(axis=1)\n",
        "X = X[inlier_idx]\n",
        "y = y[inlier_idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skK0LzIa9GF0"
      },
      "source": [
        "# Stacking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8kDlApDiv78"
      },
      "source": [
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RF6GQF9Bjf6f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9JoPnyqj0E6"
      },
      "source": [
        "from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "import lightgbm as lgb\n",
        "from vecstack import stacking\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def f1_score_wrap(y_true, y_pred):\n",
        "    return f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "def NNClf():\n",
        "    clf = Sequential()\n",
        "    clf.add(Dense(100, activation='sigmoid', input_dim=23))\n",
        "    clf.add(Dense(100, activation='sigmoid'))\n",
        "    clf.add(Dense(100, activation='sigmoid'))\n",
        "    clf.add(Dense(4, activation='softmax'))\n",
        "    clf.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=[tfa.metrics.F1Score(average='weighted',num_classes=4)])\n",
        "    return clf\n",
        "    \n",
        "models = [\n",
        "    KerasClassifier(NNClf,epochs=10, batch_size=500, verbose=0),\n",
        "    HistGradientBoostingClassifier(),\n",
        "    lgb.LGBMClassifier(),\n",
        "    XGBClassifier()\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgOztWWOEyxw",
        "outputId": "bc4cad4c-fb10-4305-c417-b0cabcb5c617"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "# X_train, X_test, y_train, y_test = X, X_final, y, []\n",
        "\n",
        "cat_col = ['tier_2', 'tier_3', 'gender_2']\n",
        "cont_col = [c for c in selected_columns if c not in cat_col ]\n",
        "\n",
        "X_train_cont = X_train[cont_col]\n",
        "X_test_cont = X_test[cont_col]\n",
        "scaler = StandardScaler()\n",
        "# scaler = QuantileTransformer(output_distribution='normal')\n",
        "\n",
        "X_train[cont_col] = scaler.fit_transform(X_train_cont.values)\n",
        "X_test[cont_col] = scaler.transform(X_test_cont.values)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:1734: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(loc, value[:, i].tolist())\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:1734: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(loc, value[:, i].tolist())\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYJbvSeeH7_8",
        "outputId": "19c5fe1f-f0a9-4106-ec65-14a7377fd7b7"
      },
      "source": [
        "X_train.shape, y_train.shape, X_test.shape, len(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((354286, 23), (354286,), (39366, 23), 39366)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEPGGD7fj-q_",
        "outputId": "72620dc0-9108-4110-fcc7-0f88af54cccb"
      },
      "source": [
        "SUBSET_SIZE = -1\n",
        "\n",
        "S_train, S_test = stacking(models,                     # list of models\n",
        "                           X_train[:SUBSET_SIZE].values, y_train[:SUBSET_SIZE].values, X_test.values,   # data\n",
        "                        #    X_train_std, y_train, X_test_std,   # data\n",
        "                           regression=False,           # classification task (if you need \n",
        "                                                       #     regression - set to True)\n",
        "                           mode='oof_pred_bag',        # mode: oof for train set, predict test \n",
        "                                                       #     set in each fold and vote\n",
        "                           needs_proba=False,          # predict class labels (if you need \n",
        "                                                       #     probabilities - set to True) \n",
        "                           save_dir=\".\",              # do not save result and log (to save \n",
        "                                                       #     in current dir - set to '.')\n",
        "                           metric=f1_score_wrap,      # metric: callable\n",
        "                           n_folds=4,                  # number of folds\n",
        "                           stratified=True,            # stratified split for folds\n",
        "                           shuffle=True,               # shuffle the data\n",
        "                           random_state=0,             # ensure reproducibility\n",
        "                           verbose=2) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "task:         [classification]\n",
            "n_classes:    [4]\n",
            "metric:       [f1_score_wrap]\n",
            "mode:         [oof_pred_bag]\n",
            "n_models:     [4]\n",
            "\n",
            "model  0:     [KerasClassifier]\n",
            "    fold  0:  [0.70714336]\n",
            "    fold  1:  [0.68155319]\n",
            "    fold  2:  [0.72353143]\n",
            "    fold  3:  [0.68561398]\n",
            "    ----\n",
            "    MEAN:     [0.69946049] + [0.01696197]\n",
            "    FULL:     [0.70318969]\n",
            "\n",
            "model  1:     [HistGradientBoostingClassifier]\n",
            "    fold  0:  [0.76147324]\n",
            "    fold  1:  [0.76343683]\n",
            "    fold  2:  [0.76116607]\n",
            "    fold  3:  [0.76088465]\n",
            "    ----\n",
            "    MEAN:     [0.76174020] + [0.00100142]\n",
            "    FULL:     [0.76174185]\n",
            "\n",
            "model  2:     [LGBMClassifier]\n",
            "    fold  0:  [0.76661094]\n",
            "    fold  1:  [0.76777284]\n",
            "    fold  2:  [0.76788292]\n",
            "    fold  3:  [0.76729118]\n",
            "    ----\n",
            "    MEAN:     [0.76738947] + [0.00050156]\n",
            "    FULL:     [0.76738658]\n",
            "\n",
            "model  3:     [XGBClassifier]\n",
            "    fold  0:  [0.74947944]\n",
            "    fold  1:  [0.75026480]\n",
            "    fold  2:  [0.75036135]\n",
            "    fold  3:  [0.74885028]\n",
            "    ----\n",
            "    MEAN:     [0.74973897] + [0.00061664]\n",
            "    FULL:     [0.74974138]\n",
            "\n",
            "Result was saved to [./[2020.12.05].[12.03.35].242080.02a4a4.npy]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cu3pRDgun1Be"
      },
      "source": [
        "model = HistGradientBoostingClassifier()\n",
        "\n",
        "model = model.fit(S_train, y_train[:SUBSET_SIZE])\n",
        "\n",
        "y_pred = model.predict(S_test)\n",
        "\n",
        "# print('Final prediction score: [%.8f]' % f1_score(y_test, y_pred, average=\"weighted\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mlqwo2zdDkHw"
      },
      "source": [
        "pd.DataFrame(y_pred).to_csv(\"output.csv\",header=False,index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kyaJqnZsnF-",
        "outputId": "af3aae40-3436-40a8-9cdb-73a1925cf801"
      },
      "source": [
        "!pip install tensorflow-addons"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.6/dist-packages (0.8.3)\n",
            "Requirement already satisfied: typeguard in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons) (2.7.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftdPV7waxKJy"
      },
      "source": [
        "#TabNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOY8_1K8xJvV",
        "outputId": "557143c3-0cbb-4d81-951d-11eb64bf1f63"
      },
      "source": [
        "!pip install pytorch-tabnet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-tabnet\n",
            "  Downloading https://files.pythonhosted.org/packages/50/66/6750481a520cc0c137777da1d84c8d892624520d660a258aa7f8498eaaab/pytorch_tabnet-2.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.6/dist-packages (from pytorch-tabnet) (1.4.1)\n",
            "Requirement already satisfied: torch<2.0,>=1.2 in /usr/local/lib/python3.6/dist-packages (from pytorch-tabnet) (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.6/dist-packages (from pytorch-tabnet) (1.18.5)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.6/dist-packages (from pytorch-tabnet) (0.22.2.post1)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.36 in /usr/local/lib/python3.6/dist-packages (from pytorch-tabnet) (4.41.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch<2.0,>=1.2->pytorch-tabnet) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch<2.0,>=1.2->pytorch-tabnet) (0.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch<2.0,>=1.2->pytorch-tabnet) (0.16.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (0.17.0)\n",
            "Installing collected packages: pytorch-tabnet\n",
            "Successfully installed pytorch-tabnet-2.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeTfn6MJxP09",
        "outputId": "6d71e7ce-9639-4d25-cd99-1f12bee1ef0a"
      },
      "source": [
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "\n",
        "clf = TabNetClassifier(\n",
        "    n_d = 32,\n",
        "    n_a = 32,\n",
        "    n_steps=5,\n",
        ") \n",
        "clf.fit(\n",
        "  X_train.values, y_train.values,\n",
        "  eval_set=[(X_test.values, y_test.values)]\n",
        ")\n",
        "preds = clf.predict(X_final.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device used : cuda\n",
            "epoch 0  | loss: 0.67261 | val_0_accuracy: 0.6942  |  0:00:38s\n",
            "epoch 1  | loss: 0.61209 | val_0_accuracy: 0.5349  |  0:01:17s\n",
            "epoch 2  | loss: 0.60428 | val_0_accuracy: 0.70233 |  0:01:56s\n",
            "epoch 3  | loss: 0.60214 | val_0_accuracy: 0.64604 |  0:02:36s\n",
            "epoch 4  | loss: 0.60078 | val_0_accuracy: 0.56617 |  0:03:17s\n",
            "epoch 5  | loss: 0.60003 | val_0_accuracy: 0.28144 |  0:03:58s\n",
            "epoch 6  | loss: 0.59974 | val_0_accuracy: 0.38782 |  0:04:40s\n",
            "epoch 7  | loss: 0.59952 | val_0_accuracy: 0.65831 |  0:05:19s\n",
            "epoch 8  | loss: 0.59837 | val_0_accuracy: 0.70515 |  0:05:57s\n",
            "epoch 9  | loss: 0.5987  | val_0_accuracy: 0.70335 |  0:06:35s\n",
            "epoch 10 | loss: 0.59732 | val_0_accuracy: 0.34725 |  0:07:14s\n",
            "epoch 11 | loss: 0.5968  | val_0_accuracy: 0.7069  |  0:07:52s\n",
            "epoch 12 | loss: 0.59768 | val_0_accuracy: 0.34733 |  0:08:30s\n",
            "epoch 13 | loss: 0.59651 | val_0_accuracy: 0.70927 |  0:09:09s\n",
            "epoch 14 | loss: 0.59457 | val_0_accuracy: 0.51329 |  0:09:48s\n",
            "epoch 15 | loss: 0.59382 | val_0_accuracy: 0.33808 |  0:10:27s\n",
            "epoch 16 | loss: 0.59284 | val_0_accuracy: 0.42605 |  0:11:05s\n",
            "epoch 17 | loss: 0.59249 | val_0_accuracy: 0.35007 |  0:11:45s\n",
            "epoch 18 | loss: 0.59282 | val_0_accuracy: 0.50981 |  0:12:24s\n",
            "epoch 19 | loss: 0.59499 | val_0_accuracy: 0.71125 |  0:13:04s\n",
            "epoch 20 | loss: 0.59171 | val_0_accuracy: 0.48796 |  0:13:43s\n",
            "epoch 21 | loss: 0.59142 | val_0_accuracy: 0.44683 |  0:14:22s\n",
            "epoch 22 | loss: 0.59055 | val_0_accuracy: 0.41406 |  0:15:01s\n",
            "epoch 23 | loss: 0.58997 | val_0_accuracy: 0.42684 |  0:15:40s\n",
            "epoch 24 | loss: 0.58948 | val_0_accuracy: 0.40263 |  0:16:19s\n",
            "epoch 25 | loss: 0.58993 | val_0_accuracy: 0.46172 |  0:16:58s\n",
            "epoch 26 | loss: 0.58909 | val_0_accuracy: 0.4025  |  0:17:37s\n",
            "epoch 27 | loss: 0.5883  | val_0_accuracy: 0.54486 |  0:18:16s\n",
            "epoch 28 | loss: 0.58789 | val_0_accuracy: 0.49926 |  0:18:56s\n",
            "epoch 29 | loss: 0.5872  | val_0_accuracy: 0.43065 |  0:19:35s\n",
            "\n",
            "Early stopping occured at epoch 29 with best_epoch = 19 and best_val_0_accuracy = 0.71125\n",
            "Best weights from best epoch are automatically used!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ug4LEiJI0krw",
        "outputId": "7130f68f-2683-4b0e-df69-a35d4ea75243"
      },
      "source": [
        "preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 4, 4, ..., 1, 4, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    }
  ]
}